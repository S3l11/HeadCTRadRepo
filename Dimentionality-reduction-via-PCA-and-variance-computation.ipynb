{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNcGo992iki07CPX/ibSH1u"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"Iz2GH3w5w3nI"},"outputs":[],"source":["import os\n","import zipfile\n","import numpy as np\n","import pandas as pd\n","\n","from PIL import Image\n","from sklearn.decomposition import PCA\n","from sklearn.preprocessing import StandardScaler"]},{"cell_type":"code","source":["def unzip_images(zip_path, extract_to):\n","\n","    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n","        zip_ref.extractall(extract_to)"],"metadata":{"id":"BopuE78T0NRB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def load_and_resize_images(image_paths, target_size):\n","    images = []\n","    original_images = []\n","    original_indices = []\n","\n","    for idx, path in enumerate(image_paths):\n","        try:\n","            img = Image.open(path).convert('L')\n","            img_resized = img.resize(target_size)\n","            img_array = np.array(img_resized).flatten()\n","            images.append(img_array)\n","            original_images.append(img)\n","            original_indices.append(idx)\n","        except Exception as e:\n","            print(f\"Error in uploading image {path}: {e}\")\n","\n","    return np.array(images), original_images, original_indices"],"metadata":{"id":"D1jT08J0xQO5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def save_selected_frames(selected_frames, original_images, original_indices, output_dir, tac_name):\n","    tac_output_dir = os.path.join(output_dir, tac_name)\n","    os.makedirs(tac_output_dir, exist_ok=True)\n","\n","    for idx, frame_idx in enumerate(selected_frames):\n","        img = original_images[frame_idx]\n","        original_index = original_indices[frame_idx] + 1\n","        output_path = os.path.join(tac_output_dir, f\"Slice{original_index:04d}.jpg\")\n","        img.save(output_path)"],"metadata":{"id":"w1q7tvjsxfre"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def save_frame_features(features, frame_indices, original_indices, output_dir, tac_name):\n","    tac_output_dir = os.path.join(output_dir, tac_name)\n","    os.makedirs(tac_output_dir, exist_ok=True)\n","    feature_file_path = os.path.join(tac_output_dir, \"SliceFeatures.csv\")\n","    features_df = pd.DataFrame(features[frame_indices])\n","    features_df['original_index'] = [original_indices[i] + 1 for i in frame_indices]\n","    features_df.to_csv(feature_file_path, index=False)"],"metadata":{"id":"uH9sHXU4zU77"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tac_directory = '' # input dir containing scans\n","\n","output_directory = '' # output dir for PCA-reduced groups of 5 slices per scan\n","\n","os.makedirs(output_directory, exist_ok=True)"],"metadata":{"id":"q7BXNwxhxrJ3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["target_size = (224, 224)\n","\n","all_images = []\n","all_original_images = []\n","all_original_indices = []\n","tac_names = []\n","\n","for tac in os.listdir(tac_directory):\n","    tac_path = os.path.join(tac_directory, tac)\n","    if os.path.isdir(tac_path):\n","        zip_file_path = None\n","\n","        for file in os.listdir(tac_path):\n","            if file.endswith('.zip'):\n","                zip_file_path = os.path.join(tac_path, file)\n","                break\n","\n","        if zip_file_path:\n","            extract_path = os.path.join(tac_path, 'Extracted')\n","            os.makedirs(extract_path, exist_ok=True)\n","            unzip_images(zip_file_path, extract_path)\n","\n","            image_paths = [os.path.join(extract_path, img) for img in os.listdir(extract_path) if img.endswith('.jpg')]\n","            if image_paths:\n","                tac_images, original_images, original_indices = load_and_resize_images(image_paths, target_size)\n","\n","                variances = np.var(tac_images, axis=1)\n","                high_variance_indices = np.where(variances > np.percentile(variances, 20))[0]\n","                tac_images = tac_images[high_variance_indices]\n","                original_images = [original_images[i] for i in high_variance_indices]\n","                original_indices = [original_indices[i] for i in high_variance_indices]\n","\n","                all_images.append(tac_images)\n","                all_original_images.append(original_images)\n","                all_original_indices.append(original_indices)\n","                tac_names.append(tac)\n","\n","for tac_images, original_images, original_indices, tac_name in zip(all_images, all_original_images, all_original_indices, tac_names):\n","    if len(tac_images) > 0:\n","        scaler = StandardScaler()\n","        tac_images_scaled = scaler.fit_transform(tac_images)\n","\n","        pca = PCA(n_components=0.95)\n","        tac_images_pca = pca.fit_transform(tac_images_scaled)\n","\n","        explained_variances = np.var(tac_images_pca, axis=1)\n","        num_top_frames = 5\n","        top_frame_indices = np.argsort(explained_variances)[-num_top_frames:]\n","\n","        save_selected_frames(top_frame_indices, original_images, original_indices, output_directory, tac_name)\n","        save_frame_features(tac_images_pca, top_frame_indices, original_indices, output_directory, tac_name)\n","\n","print(\"Slices and features selected and stored as new data.\")"],"metadata":{"id":"rUGcz__oxpO9"},"execution_count":null,"outputs":[]}]}